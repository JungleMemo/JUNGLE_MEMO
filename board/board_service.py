from board_repository import UserRepository  # ë ˆí¬ì§€í† ë¦¬ import
from datetime import datetime

#yj
import requests
from bs4 import BeautifulSoup
import nltk
from urllib.parse import urlparse

nltk.download("punkt")

class UserService:
    @staticmethod
    def create_board(url, writer, keyword, like=0):
        """
        ê¸€ ì‘ì„± ì„œë¹„ìŠ¤
        :param url: ê²Œì‹œê¸€ URL
        :param writer: ì‘ì„±ì
        :param title: ì œëª©
        :param keyword: í‚¤ì›Œë“œ
        :param summary: ìš”ì•½
        :param like: ì¢‹ì•„ìš” ìˆ˜ (ê¸°ë³¸ê°’ 0)
        :return: ìƒì„±ëœ ê²Œì‹œê¸€ ID
        """
        title = UserService.extract_title(url)
        summary = UserService.extract_summary(url, keyword)
        create_time = datetime  # í˜„ì¬ UTC ì‹œê°„ ê¸°ë¡
        return UserRepository.create_board(url, writer, title, keyword, summary, like, create_time)

    @staticmethod
    def find_by_writer(writer):
        """
        ì‘ì„±ìì˜ ê¸€ ê²€ìƒ‰
        :param writer: ê²€ìƒ‰í•  ì‘ì„±ì
        :return: í•´ë‹¹ ì‘ì„±ìì˜ ê²Œì‹œê¸€ (ì—†ìœ¼ë©´ None)
        """
        return UserRepository.find_by_writer(writer)


#yj
    @staticmethod
    def extract_content_text(url):
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=5)
        
        if response.status_code != 200:
            print (f"Failed to fetch {url}. Status code: {response.status_code}")
            return ""
        
        soup = BeautifulSoup(response.text, "html.parser")
        text = soup.get_text(seperator=" ", strip=True)
        text = " ".join(text.split())
        return text.strip()
    
    @staticmethod
    def extract_summary(url, keyword):
        # ğŸ”‘ í‚¤ì›Œë“œ ì…ë ¥ í›„ ë¬¸ì¥ ì¶”ì¶œ
        text = UserService.extract_content_text(url)
        my_keyword = keyword.strip().lower()
        sentences = nltk.sent_tokenize(text)
        # filtered_sentences = [s for s in sentences if keyword in s.lower()][:3]
        filtered_sentences = [s.strip() for s in sentences if my_keyword in s.lower()]
        filtered_sentences = [s for s in filtered_sentences if s]  # âœ… ê³µë°±ë§Œ ìˆëŠ” ë¬¸ì¥ ì œê±°

        print(f"\nì›¹í˜ì´ì§€ ë³¸ë¬¸ (ìš”ì•½ëœ ë‚´ìš©):")
        if filtered_sentences:
            for i, sentence in enumerate(filtered_sentences[:3], 1):
                print(f"{i}. {sentence}")
        else:
            print("í•´ë‹¹ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    @staticmethod
    def extract_title(url):
        response = requests.get(url) 
        soup = BeautifulSoup(response.text, "html.parser") 
        title = soup.title.string.strip() if soup.title else "ì œëª© ì—†ìŒ"
        return title



    